---
title: 'Predicting the Operational Status of Tanzanian Water Pumps'
subtitle: 'Random Forest'
author: "Thomas Skowronek"
date: "February 09, 2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---


```{r setup-layout, cache=FALSE, echo=FALSE}
# Define the report layout.
library(knitr)

# Set global chunk options: images sizes for html and docx
output <- opts_knit$get("rmarkdown.pandoc.to")

if (output=="html") opts_chunk$set(fig.width=10,  fig.height=6)
if (output=="docx") opts_chunk$set(fig.width=10,  fig.height=6)

# Set the printable width
options(width = 95)
```
\newline


# Setup
Set the working directory, clear all existing objects in the workspace and set the seed for reproducibility.  Lastly, load the necessary libraries.
```{r env-config, warning=FALSE, message=FALSE}
# Set the working directory
setwd("./")

# Clear all existing objects in the workspace
rm(list = ls())

# Set the seed for reproducible results
set.seed(1009)

# Load libraries
library(dplyr)
library(randomForest)
library(caret)
```
\newline


# Load the Datasets
```{r load-data}
# Variable name: training.data
source("./modules/load-training-data.R")
str(training.data)
summary(training.data)

# Variable name: test.values
source("./modules/load-test-data.R")
str(test.values)
summary(test.values)
```
\newline


# Split the Training Data
Create training and testing subsets of the data.
```{r train-test}
# Create an 80/20 split
random.idx <- createDataPartition(training.data$status_group, p = .80, list = FALSE)
pump.train <- training.data[ random.idx, ]
pump.test <- training.data[-random.idx, ]

# Verify similar proportions of status_group for training vs.testing
prop.table(table(pump.train$status_group))
prop.table(table(pump.test$status_group))
```
\newline


# Random Forest Model #1
Create random forest model using a subset of attributes.
```{r model-1}
pump.model.1 <- randomForest(status_group ~ longitude + latitude + extraction_type_group + construction_year +
                                quality_group + quantity + waterpoint_type, 
                              data = pump.train, importance = TRUE, ntree = 10, nodesize = 2)

# Inspect the model
pump.model.1
#summary(pump.model.1)

# Examine the importance of the predictor attributes
importance(pump.model.1)
varImpPlot(pump.model.1)

# Use the model to create predictions against the test dataset
pump.predict.1 <- predict(pump.model.1, select(pump.test, -status_group))

# Evaluate the model using a confusion matrix
confusionMatrix(pump.predict.1, pump.test$status_group, mode = "everything")
```
\newline


# Random Forest Model #2
Create random forest model using a larger subset of attributes and trees.
```{r model-2}
ptm.start <- proc.time()

pump.model.2 <- randomForest(status_group ~ basin + region + permit + extraction_type_class + quality_group + 
                               quantity + source + waterpoint_type + population + amount_tsh + gps_height + 
                               district_code + scheme_management + payment + longitude + latitude,
                              data = pump.train, importance = TRUE, ntree = 500)

# Inspect the model
pump.model.2
#summary(pump.model.2)

# Examine the importance of the predictor attributes
importance(pump.model.2)
varImpPlot(pump.model.2)

# Use the model to create predictions against the test dataset
pump.predict.2 <- predict(pump.model.2, select(pump.test, -status_group))

# Evaluate the model using a confusion matrix
confusionMatrix(pump.predict.2, pump.test$status_group, mode = "everything")

# Use the model to create predictions against the real test dataset
pump.predict.test.2 <- predict(pump.model.2, select(test.values, -id))

# Create submission for Data Driven
submission.2 <- data.frame(id = test.values$id, status_group = pump.predict.test.2)
write.csv(submission.2, file = "../data/random-forest-model-2.csv", row.names=FALSE)

ptm.end <- proc.time() - ptm.start
ptm.end[3] / 60
```
\newline


# Random Forest Model #3
Create random forest model using 10-fold cross validation.
```{r model-3}
ptm.start <- proc.time()


pump.model.3 <- train(status_group ~ basin + region + permit + extraction_type_class + quality_group + 
                 quantity + source + waterpoint_type + population + amount_tsh + gps_height + 
                 district_code + scheme_management + payment + longitude + latitude, 
                 data = training.data, method = "rf", trControl = trainControl(method = "cv", number = 10))


# Inspect the model
pump.model.3
#summary(pump.model.3)

# Examine the importance of the predictor attributes
varImp(pump.model.3, scale = FALSE)
plot(pump.model.3, top = 20)

# Use the model to create predictions against the test dataset
pump.predict.3 <- predict(pump.model.3, select(pump.test, -status_group))

# Evaluate the model using a confusion matrix
confusionMatrix(pump.predict.3, pump.test$status_group, mode = "everything")

# Use the model to create predictions against the real test dataset
pump.predict.test.3 <- predict(pump.model.3, select(test.values, -id))

# Create submission for Data Driven
submission.3 <- data.frame(id = test.values$id, status_group = pump.predict.test.3)
write.csv(submission.3, file = "../data/random-forest-model-3.csv", row.names=FALSE)

ptm.end <- proc.time() - ptm.start
ptm.end[3] / 60
```
\newline


# Random Forest Model #4
Create random forest model using 10-fold cross validation.
```{r model-4}
ptm.start <- proc.time()

predictors <- c("amount_tsh", "funder.bin", "gps_height", "installer.bin", "longitude", "latitude",
                "basin", "region", "region_code", "district_code", "lga",  "population", 
                "public_meeting", "scheme_management", "permit", "construction_year", "extraction_type", 
                "extraction_type_group", "extraction_type_class", "management", "management_group", 
                "payment", "payment_type", "water_quality", "quality_group", "quantity", 
                "quantity_group", "source", "source_type", "source_class", "waterpoint_type", 
                "waterpoint_type_group", "status_group")

train.subset <- training.data %>% select(predictors)

pump.model.4 <- train(status_group ~ ., data = train.subset, method = "rf", trControl = trainControl(method = "cv", number = 10))


# Inspect the model
pump.model.4
#summary(pump.model.4)

# Examine the importance of the predictor attributes
varImp(pump.model.4, scale = FALSE)
plot(pump.model.4, top = 20)

# Use the model to create predictions against the test dataset
pump.predict.4 <- predict(pump.model.4, select(pump.test, -status_group))

# Evaluate the model using a confusion matrix
confusionMatrix(pump.predict.4, pump.test$status_group, mode = "everything")

# Use the model to create predictions against the real test dataset
pump.predict.test.4 <- predict(pump.model.4, select(test.values, -id))

# Create submission for Data Driven
submission.4 <- data.frame(id = test.values$id, status_group = pump.predict.test.4)
write.csv(submission.4, file = "../data/random-forest-model-4.csv", row.names=FALSE)

ptm.end <- proc.time() - ptm.start
ptm.end[3] / 60
```
\newline


# Random Forest Model #5
Create random forest model using 10-fold cross validation.
```{r model-5}
ptm.start <- proc.time()

predictors <- c("amount_tsh", "funder.bin", "gps_height", "installer.bin", "longitude", "latitude",
                "basin", "region", "region_code", "district_code", "lga",  "population", 
                "public_meeting", "scheme_management", "permit", "construction_year", "extraction_type", 
                "extraction_type_group", "extraction_type_class", "management", "management_group", 
                "payment", "payment_type", "water_quality", "quality_group", "quantity", 
                "quantity_group", "source", "source_type", "source_class", "waterpoint_type", 
                "waterpoint_type_group", "status_group")

train.subset <- training.data %>% select(predictors)

pump.model.5 <- train(status_group ~ ., data = train.subset, method = "rf", tuneLength = 5, 
                      trControl = trainControl(method = "repeatedcv", number = 5), 
                      metric = "Kappa")

# Inspect the model
pump.model.5
#summary(pump.model.5)

# Examine the importance of the predictor attributes
varImp(pump.model.5, scale = FALSE)
plot(pump.model.5, top = 20)

# Use the model to create predictions against the test dataset
pump.predict.5 <- predict(pump.model.5, select(pump.test, -status_group))

# Evaluate the model using a confusion matrix
confusionMatrix(pump.predict.5, pump.test$status_group, mode = "everything")

# Use the model to create predictions against the real test dataset
pump.predict.test.5 <- predict(pump.model.5, select(test.values, -id))

# Create submission for Data Driven
submission.5 <- data.frame(id = test.values$id, status_group = pump.predict.test.5)
write.csv(submission.5, file = "../data/random-forest-model-5.csv", row.names=FALSE)

ptm.end <- proc.time() - ptm.start
ptm.end[3] / 60
```


